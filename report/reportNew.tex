\documentclass[12pt]{article}
\usepackage{graphicx} % for inserting images
\usepackage[utf8]{inputenc} % for good practice
\usepackage{amsmath} % for equations
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage[ruled,linesnumbered]{algorithm2e}
\usepackage{setspace}
\usepackage{siunitx}
\usepackage{csquotes}
\usepackage{changepage}
\usepackage{subfig}
\usepackage{url}
\usepackage{subcaption}
\usepackage{rotating}
\usepackage{tikz}
\sisetup{output-exponent-marker=\ensuremath{\mathrm{e}}}
\usepackage[
backend=biber,
sorting=ynt
]{biblatex}
\addbibresource{references.bib}

\title{\textit{Document Classification in \\Public Administration}}
\author{Gugole Nicola\\Pasquali Alex\\Piccoli Elia}
\date{September, 2021}

\begin{document}
\begin{titlepage}
	\maketitle
	\pagenumbering{gobble}
   \begin{center}
	\vspace{0.5cm}
       Final project for the\\ \textit{Human Language Technologies}\\ course
       \vfill	     
       \includegraphics[width=0.2\textwidth]{unipi.png}\\
       University of Pisa\\
       Artificial Intelligence\\
       A.Y. 2020/2021\\
   \end{center}
\end{titlepage}
\newpage
{\footnotesize \tableofcontents}
\pagenumbering{arabic}
\newpage

\section{Project Purpose}\label{sec:projectpurpose}
The project was developed in association with \textit{Compagnia Trasporti Toscana (CTT)}, which is the company that handles the public transportation in Tuscany, and Doc. Riccardo Franchi (Corporate Manager), who was our reference inside the company.
The focus of the project was to improve the document archiving process in compliance with the \textit{Protocollo Informatico Italian} law. In fact, the user of public administration, in order to archive a protocol, has to fill various fields (\hyperref[fig:interface]{\textbf{Figure 3}}), in particular: needs to write a summary of the contents of the document (\textit{Oggetto}), pick the correct document repository for the office (\textit{Contenitore}) and then choose the correct class among many. The different classes are stored in a hierarchical structure (\textit{Titolario}, \hyperref[fig:classinterface]{\textbf{Figure 4}}), where going from higher to lower levels a more precise description of the class is provided. The user, in order to select the class, has to navigate through the various levels of the hierarchy. Each office is responsible for the administrative processes identified by the classes of its competence. This results in a mechanic and repetitive task, that the user must do each time a new protocol arrives. Obviously, this process is not error-free since it is heavily influenced by the user competence, each error affect the quality of the administrative process.\\

The purpose of the project is to speedup and provide soundness to the class selection task providing the user with a suggestion formed of a small set of classes where the document is more likely to be classified.
In this way, without going through the hierarchy, the user is able to exploit the model prediction.
In order to properly build the model architecture a key point was to define input and output. The \textit{output} can be easily defined as a distribution probability over the different classes. The \textit{input}, instead, was limited to only a small subset of available information. As a matter of facts, the input is composed by two elements: \textit{Oggetto} and \textit{Contenitore}.
\hyperref[sec:model-desc]{\textbf{Section \ref{sec:model-desc}}} will provide more information on how the two different fields are handled. An important aspect that will play a key role is the \textit{inference time}, in fact the model needs to be fast in order to give an almost instant feedback to the user that would otherwise need to search among the hierarchy.\\

The analysis will be divided into different sections. Starting from an in depth analysis of the dataset in \hyperref[sec:dataset]{\textbf{Section \ref{sec:dataset}}}, followed by the analysis of the two main task of the project. \hyperref[sec:1lev-model]{\textbf{Section \ref{sec:1lev-model}}} will cover the easier task using only the first level of the classes hierarchy resulting in a probability distribution of \textit{15} elements. \hyperref[sec:2lev-model]{\textbf{Section \ref{sec:2lev-model}}}, instead, will focus on the second level of the tree leading to \textit{118} possible classes. The remaining sections will analyze different architectures, the results over a new set of data and some final considerations.

\section{Dataset Preprocessing}\label{sec:dataset}
\textit{CTT} company kindly offered us its entire dataset, with the hard constraint of taking the data starting from January 2018 because of a change of class tree which happened at the time. The raw dataset consisted of \textbf{~100000} samples and needed a meticolous preprocessing to avoid privacy issues. Further parsing was also needed to generalize otherwise futile vocabulary entries.

\subsection{Dataset Features Extraction}
The dataset was composed initially of many features comprising date of insertion, object, office, class code, class name and various ids as external keys to other dataset tables.\\Of these only a subset was kept for the model input, as explained in \hyperref[sec:projectpurpose]{\textbf{Section \ref{sec:projectpurpose}}}. The dataset is therefore composed of 4 features:
\begin{itemize}
    \item \textbf{Oggetto:} string defining a summary of the document which is being classified.
    \item \textbf{Contenitore:} string representing the document repository where the protocol is archived. From now on, for simplicity sake, the document repository will be referred to as \textit{office}.
    \item \textbf{PrimoLivello:} integer ranging from 1-15, ground truth for first level classification.
    \item \textbf{SecondoLivello:} integer with a value range depending on the first level (each first level may have a different subtree), combined with \textit{PrimoLivello} gives a ground truth for second level classification.
\end{itemize}

\subsection{Dataset Cleaning}
A series of operations was applied in order to privatize and generalize the data as much as possible, trying at the same time to keep highest possible variability for better learning.

Exploring the samples and discussing with Doc. Franchi lead to the individuation of personal data as well as offices for which the task is useless. Two situations in particular lead to a first skimming of the dataset:
\begin{itemize}
    \item A specific class (\textit{Permessi sindacali}) contained a notable amount of full names, and was therefore dropped under Doc. Franchi advice. 
    \item An ensemble of protocols all involving \textit{Fatture} was dropped due to the uselessness of a classifier in that case. The documents involving these protocols are in fact not inserted by hand but by an automatized process.
\end{itemize}
This first process left us with a dataset composed of \textbf{60509} samples, which we furthered cleaned and treated by transforming the input features (\textit{Oggetto} and \textit{Contenitore}) by stripping the resulting samples from any unnecessary leading/trailing whitespace. 

\subsection{Dataset Balancing} \label{sec:dataset-balancing}
The implicit different load of documents per class in a real world application such as this one leads to a not surprising fact, the unbalancing in number of samples per class. An unbalanced dataset is not ideal for the task, since the model will have a disproportion of learning material with a consequent lower precision in less populated classes. \\We therefore opted for a balancing process on the dataset, applying a careful stratification to low populated classes and a reduction to exaggeratedly populated ones. The main aim of the process was to result in a more balanced first level dataset (the second level of the tree is too unbalanced and sparse) while maintaining the data distribution. 
\begin{itemize}
    \item \textbf{Stratification:} applied to class 3,5,11 and 12. Unfortunately we could not automatically generate new samples in the \textit{Oggetto} field because of its textual nature, nevertheless we tried to higher the number of samples and their variability by creating new rows where \textit{Oggetto} and \textit{Contenitore} are chosen independently and randomly from the pool of \textit{Oggetti} and \textit{Contenitori} of a specific second level class. This augmentation assured the correctness of the dataset both for the first level and the second level task. 
    \item \textbf{Reduction:} applied to class 6,14. Randomly chosen samples were dropped. Randomization was preferred to cutting beginning/end of dataset for a higher probability in maintaining the interclass distribution.
\end{itemize}
The result of the balancing process can be appreciated in \hyperref[fig:before]{\textbf{Figure 1a}} and \hyperref[fig:after]{\textbf{Figure 1b}}, leaving in the final dataset a total of \textbf{39940} samples.
\begin{figure}[!tbp]
  \centering
  \subfloat[Before balancing]{\includegraphics[width=0.4\textwidth]{before_balancing.png}\label{fig:before}}
  \hfill
  \subfloat[After balancing]{\includegraphics[width=0.4\textwidth]{after_balancing.png}\label{fig:after}}
\caption{Class distribution}
\end{figure}

\subsection{Dataset Parsing}
Data parsing is a fundamental aspect when working with Natural Language, therefore we applied a last series of filtering and mapping to our data before feeding it to the model. Because of the predetermined and fixed range of values for \textit{Contenitore}, we decided to apply the parsing only to the \textit{Oggetto} field, definitely more dynamic than the other. The treating of \textit{Contenitore} will be further discussed in \hyperref[sec:office-module]{\textbf{Section 3.1.2}}.
\\The dataset has therefore to pass through a last procedure before being ready for training:
\begin{itemize}
    \item \textbf{Filtering:} Generalizing the data from futile or private information, replacing all dates, hours, emails and generic numbers with more general tokens, namely \textless DATE\textgreater, \textless HOUR\textgreater, \textless EMAIL\textgreater, \textless NUMBER\textgreater. Particular care was put into the email processing, a process which was manually checked to ensure the avoidance of personal data in the final training dataset, which might have happened due to the possible incorrectness of human written text.
    \item \textbf{Tokenization:} Splitting the data in single words. A particularity here stands in the need for a fixed number of words in the processed \textit{Oggetto} field. The use of a Transformer (further introduced in \hyperref[sec:object-module]{\textbf{Section 3.1.1}}) implies in our case an Embedding Layer for which a fixed input dimension is required. We therefore studied the \textit{Oggetto} length, noticing how a relevant amount of data has little length (a statistical analysis can be appreciated in \hyperref[fig:objectlength]{\textbf{Figure 2}}) and we settled for the maximum possible \textit{Oggetto} length (\textbf{95}). Sentences with less than \textbf{95} tokens are filled to reach the correct length with special padding tokens (\textless PAD\textgreater), handled by the \textit{padding mask} software component of the \textit{Transformer} object.
    \item \textbf{Encoding:} After collecting all dataset tokens a vocabulary is created and so is a mapping between token and integer. This allows for a fast encoding procedure, transforming the input sentence in an integer array which can be directly fed to the model (if a word is not present in the vocabulary it is replaced with a special token, \textless UNK\textgreater).
\end{itemize}
\begin{figure}[ht!]
    	    \begin{center}
        \includegraphics[width=0.7\textwidth]{object_length.png}
            \end{center}
        \label{fig:objectlength}
        \caption{Object length boxplot}
\end{figure}

\section{First Level Model}\label{sec:1lev-model}
In this section is described the model used to perform the classification in the first (highest, most general) level of the hierarchy of classes.

\subsection{Model Description}\label{sec:model-desc}
The class of each protocol depends on two aspects:
\begin{itemize}
    \item \textbf{Oggetto}: subject of the document, inserted by the human operator at classification time.
    \item \textbf{Contenitore}: archiving office for the protocol. Each office may archive different categories of documents, which, therefore, belong to different classes.
\end{itemize}
These two attributes are treated differently, by two different sub-models (\textbf{object module} \ref{sec:object-module} and \textbf{office module} \ref{sec:office-module}) whose outputs will be combined and fed to a multi-layer perceptron (MLP) that will perform the final classification. 
\\The full architecture can be appreciated in \hyperref[fig:archifirst]{\textbf{Figure \ref{fig:archifirst}}}.

\subsubsection{Object module}\label{sec:object-module}
Due to the textual nature of \textit{Oggetto} attribute, that can be seen as a summary of the content of the document, it is important to capture its semantics in order to understand the general matter of the document itself and perform a meaningful classification.\\
For this reason, the choice was to start from a standard \textbf{Transformer} \cite{attention_is_all_you_need, pytorch_transformer}, that is formed by a stack of encoders and decoders that work as follows:
\begin{itemize}
    \item \textbf{Encoders:} each one of the encoders of the stack has two sub-layers: the first is a \textit{multi-head self-attention} mechanism, and the second is a simple, position-wise fully connected feed-forward network.
    \item \textbf{Decoders:} each decoder in the stack, in addition to the two sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head attention over the output of the encoder stack.
    \item \textbf{Multi-head self-attention:} Instead of performing a single attention function, \textit{queries}, \textit{keys} and \textit{values} are linearly projected $h$ times with different, learnt, linear projections. The attention function is performed in parallel for each of these queries, keys and values.
\end{itemize}
Now, since the task is a classification (and not, for example, a sequence-to-sequence transduction), only the encoders of the transformer are needed.\\
The model used in the task, so, is formed by an embedding layer \cite{pytorch_embedding} followed by a \textit{TransformerEncoder} \cite{pytorch_transformerencoder}, that is a stack of encoders as described in \cite{attention_is_all_you_need}.

\subsubsection{Office module}\label{sec:office-module}
The information about the office in which the classified protocol is stored is categorical, hinting to the use of one hot encoding. Therefore the textual data becomes an array as long as the number of offices, filled with zeros apart from a single cell containing a 1.

\subsection{Performances}\label{sec:1-lvl-perf}
Experiments were carried out on a \textit{Lenovo Legion Y740-17IRHg} using its GPU (\textit{NVIDIA GeForce RTX 2080 Max-Q}) to speedup the training process. Pay attention that although trainings are executed on GPU, all timings reported for inference are referring to CPU execution of a trained model. 

Model training and validation have been carried out using a dataset with data coming from 2018 up to mid May 2021 using a \textit{Hold Out} validation strategy with an 80-20 split. \textit{Top 1} and \textit{Top 3} accuracy are used for model selection and \textit{Cross Entropy Loss} is used for learning because of the multi-class task. \textit{ReLU} is used throughout all the model as activation function.

An initial screening phase helped with fixing various hyperparameters, such as the \textit{Learning Rate} (after the initial trials we opted for a default \textit{Adam} optimizer), the use of a \textit{Multi-Head Attention} with 8 heads and a Transformer Encoder stack of 2 levels.

Our trials have therefore focused on attempting the varying of \textit{object embedding size}, \textit{number and extension of layers in final classifier} and \textit{amount of regularization}. Most relevant results are shown in \hyperref[tb:firstlevel-hyper]{\textbf{Table \ref{tb:firstlevel-hyper}}}. All attempts\footnote{obj: \textit{object module}, emb: \textit{embedding}, cls: \textit{final classifier}} are given 50 epochs but have stopped before reaching the end because of a \textit{patience} mechanism.

\begin{table}[ht!]
	    \centering
	    \scriptsize
	    \begin{tabular}{ |c|c|c|c|c| }
        \hline
        \textbf{Model} & \textbf{Obj Emb Size} & \textbf{Obj Output Size} & \textbf{Cls Topology} & \textbf{Obj/Cls Dropout} \\
        \hline
        model 25 & 256 & 256 & (obj + off, 15) & 0.777/0.777 \\
        model 35 & 256 & 256 & (obj + off, 512, 256, 15) & 0.5/0.5 \\
        model 36 & 256 & 256 & (obj + off, 256, 15) & 0.5/0.5 \\
        model 38 & 256 & 256 & (obj + off, 15) & 0.5/0.0 \\
        model 39 & 512 & 512 & (obj + off, 15) & 0.5/0.5 \\
        model 40 & 128 & 128 & (obj + off, 15) & 0.5/0.5 \\
        model 100 & 256 & 256 & (obj + off, 15) & 0.7/0.5\\
        model 104 & 256 & 256 & (obj + off, 15) & 0.7/0.2\\
        \hline
        \end{tabular}
        \captionsetup{justification   = centering}
	    \caption{\textit{Hyperparameters} of most relevant trials}
	    \label{tb:firstlevel-hyper}
\end{table}

\begin{table}[ht!]
	    \centering
	    \scriptsize
	    \begin{tabular}{ |c|c|c| }
        \hline
        \textbf{Model} & \textbf{Top1 Tr/Val} & \textbf{Top3 Tr/Val}\\
        \hline
        model 25 & 95.70/87.02 & 99.48/95.70 \\
        model 35 & 91.27/86.79 & 97.18/95.16 \\
        model 36 & 89.67/86.39 & 96.52/94.96 \\
        model 38 & 90.41/86.21 & 97.40/94.77 \\
        model 39 & 92.55/87.08 & 98.62/95.68 \\
        model 40 & 91.80/86.91 & 98.21/95.50 \\
        model 100 & 90.59/86.50 & 98.01/95.43 \\
        model 104 & 92.56/87.09 & 98.93/95.73 \\
        \hline
        \end{tabular}
        \captionsetup{justification   = centering}
	    \caption{\textit{Performances} of most relevant trials}
	    \label{tb:firstlevel-results}
\end{table}
\pagebreak

Results shown in \hyperref[tb:firstlevel-hyper]{\textbf{Table \ref{tb:firstlevel-hyper}}} and \hyperref[tb:firstlevel-results]{\textbf{Table \ref{tb:firstlevel-results}}} give rise to some interesting observations. It can be noticed in fact that the topology increment of the final classifier does not help the model to learn better and neither does increasing the object module output size (even if the worsening in accuracy is minimal). In the screening phase we also noticed a similar minimal phenomenon in worsening of accuracy when increasing the number of transformer encoders stacked onto each other. 

The selected model for the first level task is eventually \textbf{Model 104}, for which, taking a look at the model training/validation plot (\hyperref[fig:model104]{\textbf{Figure \ref{fig:model104}}}), the moment when \textit{patience} begins to rise is highlighted in red, stating the presence of an \textit{early stopping} mechanism.


\section{Second Level Model}\label{sec:2lev-model}
Here is described the model used to perform a classification that reaches the second level of the classes' hierarchy.\\
This task is more challenging because the number of classes grows significantly - from \textit{15} to \textit{118} - and the data available gets more sparse and unbalanced (also because of the increasing level of detail).

\subsection{Model Description}\label{sec:sec-lvl-desc}
The model is composed of 3 main modules:
\begin{itemize}
    \item \textbf{object module:} same as for the first level model (\hyperref[sec:object-module]{\textbf{\ref{sec:object-module}}}).
    \item \textbf{office module:} same as for the first level model (\hyperref[sec:office-module]{\textbf{\ref{sec:office-module}}}).
    \item \textbf{first level module:} consists of the pre-trained first level model (\hyperref[sec:1lev-model]{\textbf{Sec. \ref{sec:1lev-model}}}). It is loaded and its parameters are kept frozen\footnote{\label{ftnote:frozen} "Frozen" parameters (weights) are immutable/non-trainable.}.
    \item \textbf{final classifier:} a final MLP to perform the actual classification.
\end{itemize}
The input-output process works as follows:
\begin{enumerate}
    \item \label{ls:1lev_cls} A first-level classification is performed using the \textit{first level module}
    \item \label{ls:off_emb} A one hot encoding of the office is obtained through the \textit{office module}
    \item \label{ls:obj_emb} The object is passed through the \textit{object module}, the result is flattened and then sent to a FC layer\footnote{\label{ftnote:fc_layer} fully-connected / dense.} with ReLU activation function to get the desired dimensionality
    \item \label{ls:concat} The outputs of the steps \ref{ls:off_emb} and \ref{ls:obj_emb} are concatenated, some dropout is applied and the result is sent to the \textit{final classifier}
    \item \label{ls:final} Finally a bias is added to the output of the \textit{final classifier}. The output in this case is a vector of 118 cells, each cell represent a second level class, which is a refinement of a first level one. Therefore, exploiting a mapping between \textit{first-level class} and \textit{second level output index}, it is possible to add a bias accordingly to the first level prediction. In this way, the second level classes that corresponds to a more likely first level class will receive a boost.
\end{enumerate}
Exploiting the results of the first level prediction in order to guide the second level may be dangerous if the first level is not precise. In our case given the results presented in \textbf{\ref{sec:1-lvl-perf}} the first level module has a 99\% \textit{Top 3} accuracy, so the bias injected in the second level prediction in most cases does not provide any noise. \hyperref[sec:altern-lev2]{\textbf{Section \ref{sec:altern-lev2}}} analyzes the results obtained without using the first-level module output information.
\\The full architecture can be appreciated in \hyperref[fig:archisecond]{\textbf{Figure \ref{fig:archisecond}}}.

\subsection{Performances}\label{sec:secondlevelperformances}
As expected, the harder the task (in this case we enter in a situation where many more classes are present and data is a lot sparser) the lower the accuracy of the model. After a second screening phase we maintained the validation method and the same fixed parameters of the first level task (see \hyperref[sec:1-lvl-perf]{\textbf{Section \ref{sec:1-lvl-perf}}}). Because of the poorer results we decided to introduce a \textit{Top 5} accuracy. The introduction of a broader new accuracy assures a good result while still keeping an objectively restricted choice for the user. 

\begin{table}[h!]
	    \centering
	    \scriptsize
	    \begin{tabular}{ |c|c|c|c|c| }
        \hline
        \textbf{Model} & \textbf{Obj Emb Size} & \textbf{Obj Output Size} & \textbf{Cls Topology} & \textbf{Obj/Cls Dropout}\\
        \hline
        model 41 & 256 & 256 & (obj + off, 118) & 0.5/0.2\\
        model 42 & 512 & 512 & (obj + off, 118) & 0.5/0.2\\
        model 43 & 128 & 128 & (obj + off, 118) & 0.5/0.2\\
        model 45 & 256 & 256 & (obj + off, 118) & 0.7/0.7\\
        model 46 & 256 & 256 & (obj + off, 512, 256, 118) & 0.5/0.2\\
        model 200 & 256 & 256 & (obj + off, 118) & 0.7/0.5\\
        model 208 & 256 & 256 & (obj + off, 118) & 0.7/0.2\\
        \hline
        \end{tabular}
        \captionsetup{justification   = centering}
	    \caption{\textit{Hyperparameters} of \\second level task most relevant trials}
        \label{tb:secondlevel}
\end{table}

\begin{table}[h!]
	    \centering
	    \scriptsize
	    \begin{tabular}{ |c|c|c|c| }
        \hline
        \textbf{Model} & \textbf{Top1 Tr/Val} & \textbf{Top3 Tr/Val} & \textbf{Top5 Tr/Val}\\
        \hline
        model 41 & 84.67/77.75 & 94.52/87.20 & 97.35/90.53 \\
        model 42 & 67.88/65.67 & 86.83/82.12 & 92.89/87.98 \\
        model 43 & 84.14/77.71 & 94.61/86.95 & 97.15/90.30 \\
        model 45 & 67.26/65.55 & 86.96/82.17 & 92.90/87.76 \\
        model 46 & 83.95/76.93 & 94.10/86.26 & 96.98/90.10 \\
        model 200 & 76.79/76.62 & 89.13/86.26 & 93.20/89.68 \\
        model 208 & 80.30/77.71 & 91.84/87.49 & 95.31/90.54 \\
        \hline
        \end{tabular}
        \captionsetup{justification   = centering}
	    \caption{\textit{Performances} of \\second level task most relevant trials}
        \label{tb:secondlevelacc}
\end{table}

Most relevant results are shown in \hyperref[tb:secondlevel]{\textbf{Table \ref{tb:secondlevel}}} and \hyperref[tb:secondlevelacc]{\textbf{Table \ref{tb:secondlevelacc}}}. All attempts are given once again 50 epochs but have stopped before reaching the end because of a \textit{patience} mechanism.
\newline\newline
As can be appreciated, even if the \textit{Top 1} accuracy is not astonishing, \textbf{Model 208} reached a stunning 90.54\% in \textit{Top 5} validation accuracy, making it the selected model for the second level task.


\section{Relevant Attempts}
Here is provided a list of relevant alternative attempts made during the development of the project.\\
They can provide interesting comparisons and insights about the behaviour and characteristics of the main models presented in \textbf{Sections \ref{sec:1lev-model}} and \textbf{\ref{sec:2lev-model}}, as well as a different point of view on the \textit{Contenitore} field (e.g. \hyperref[sec:cls-distr-bias]{\textbf{Section \ref{sec:cls-distr-bias}}}).\\
Some models were developed for a first-level classification (\textbf{\ref{sec:altern_lev1}}) and an alternative attempt has been made for a second-level classification (\textbf{\ref{sec:altern-lev2}}).

\subsection{First level}\label{sec:altern_lev1}
Here are presented alternative models used and tested on the first level of the classes' hierarchy.\\\\
The models used in Sections \textbf{\ref{sec:1lev-model}} and \textbf{\ref{sec:2lev-model}} exploit information coming from two sources:
\begin{itemize}
    \item object: the real textual information, it is a summary of the content of the document and it is important to capture its meaning in order to correctly classify the document;
    \item office: it is more of a categorical information providing hints on the subset of classes that is more likely to contain the correct one.
\end{itemize}
The output of the \textit{object module} and the output of the \textit{office module} are concatenated to form the input of the final classifier, therefore, both are used and relevant for the final outcome, but are they both necessary?\\
To better understand if \textit{Contenitore} is really helping the model an extreme situation can be analyzed: a model where only the object is taken into account.

\subsubsection{Object only}\label{sec:obj_only}
This model tries to classify the documents considering only its object, with no information about the office that manages this protocol. This test is interesting for understanding exactly how well the model can adapt to this situation where a part of the information is missing and how important is one field compared to the other\footnote{The fields are \textit{Oggetto} (object) and \textit{Contenitore} (office).}
for the final outcome.
\paragraph{Model description}
This model simply removes the \textit{office module} (\textbf{\ref{sec:office-module}}): the object gets fed into the \textit{object module} (\textbf{\ref{sec:object-module}}) whose output is flattened and sent to a FC layer\footnotemark[\getrefnumber{ftnote:fc_layer}] to get the desired dimensionality (it is reduced).
Finally some dropout is added and the data is sent to the final classifier, which, in this case, is a single FC layer\footnotemark[\getrefnumber{ftnote:fc_layer}].
\paragraph{Performances}
Given the underlying structure of this model - \textbf{\ref{sec:object-module}} - nice results can be achieved even without the office information. This is given by the fact that the most characterizing information for the classification task is the object. While the same office can handle different classes, the same object is always classified in the same way and rarely changing few elements in the text change the classification.  Nevertheless, its performances are worse than the model presented in \hyperref[sec:1lev-model]{\textbf{Section \ref{sec:1lev-model}}} as reported in the following table.
\begin{table}[ht!]
    \begin{adjustwidth}{}{}
	    \centering
	    \small
	    \begin{tabular}{ |c|c|c| }
        \hline
        \textbf{Model} & \textbf{Top1 Tr/Val} & \textbf{Top3 Tr/Val}\\
        \hline
        model 104 & 92.56/87.09 & 98.93/95.73 \\
        Obj only & 87.42/84.13 & 96.41/94.30 \\
        \hline
        \end{tabular}
	    \label{tb:relevant-obj}
    \end{adjustwidth}
    \captionsetup{justification   = centering}
    \caption{Comparison between \textit{first-level} and \textit{object only} models}
\end{table}

\subsubsection{Office's classes distribution as injected probability}\label{sec:cls-distr-bias}
As stated in \hyperref[sec:office-module]{\textbf{Sec. \ref{sec:office-module}}}, the office where a certain document is archived is a \textbf{categorical} information.
% Obviously, the name of the office can provide some insights about the classes of documents that it manages, therefore it can be treated as a textual information as it has been done in Sections \ref{sec:1lev-model} and \ref{sec:2lev-model}.
Previously (Sections \textbf{\ref{sec:1lev-model}} and \textbf{\ref{sec:2lev-model}}), this information has been used as a 1-hot representation, where all the offices are equidistant from one another. Although this approach gave us good results, other approaches may be attempted.
This because different offices may actually share similarities, therefore a denser representation may actually be more effective for the classification task at hand.
In this specific case, similarities among offices can be reflected in similarities among the \textit{distributions of the classes associated to each office} (referred to as \textbf{classes distribution} of an office (Def. \ref{def:cls_distr})).
\newtheorem{definition}{Definition}
\begin{definition}[Classes distribution]\label{def:cls_distr}
    The \textbf{classes distribution} of an office is a vector as long as the number of classes where each entry represents how many documents archived in that office belong to each class, expressed in percentage
    \footnote{Therefore, each office will have a percentage/probability distribution over the classes.\\For example, if all the documents archived in \textit{office A} belong to class 0, its \textbf{classes distribution} will be a vector as long as the number of classes that will look like this: $[1.0,\ 0.0,\ ...,\ 0.0]$.}.
\end{definition}
Consider this example:
\begin{itemize}
    \item there are 15 classes.
    \item the entries archived in office A belong for 70\% to class 1 and 30\% to class 3.
    \item the entries archived in office B belong for 80\% to class 10 and 20\% to class 11.
    \item the entries archived in office C belong for 80\% to class 10, 10\% to class 11 and 10\% to class 13.
\end{itemize}
It is easy to conclude that office B and office C are more similar to each other than any of them is similar to office A, in the sense that they share some areas of competence and they manage similar kinds of documents.
As a consequence, their classes distribution vectors will be more similar to each other than any of them is to the classes distribution of office A.\\
This concept is exploited in the following alternative model.
\paragraph{Model description}
The \textit{object module} stays the same, but instead of concatenating its output with the \textit{office module}'s output and then sending the whole to a final MLP, the information regarding the office is injected into the model as a \textbf{probability distribution}.\\
Practically this is done in the following way:
\begin{itemize}
    \item For each input:
    \begin{itemize}
        \item Check the office (\textit{Contenitore} field);
        \item Read the classes distribution vector of that office;
        \item Perform an element-wise multiplication between the output of the final MLP and the classes distribution vector, scaling the latter accordingly to the distribution of the classes.
    \end{itemize}
\end{itemize}
This will have the effect of adding a bias to the output of the final MLP (that does not consider the office) taking into account that the office of the current entry manages only certain types of documents associated to certain classes in a certain measure.
\paragraph{Performances}
% Given the architecture of this model, that exploits the \textit{object module} and combines it with classes probabilities, the results were expected to be more or less similar to the object only scenario (\textbf{\ref{sec:obj_only}}).
% This expectation was in fact confirmed:
The model's performances are very close to the performances of the \textit{object only scenario} (\textbf{\ref{sec:obj_only}}).
The only difference between the two is the \textit{classes distribution} (Def. \ref{def:cls_distr}): this can affect model prediction by "boosting" some classes which are more likely to be the correct ones.
Since the office information is not a perfect oracle
\footnote{Due to human error during the classification process.}, this may introduce some noise into the model, leading to slightly worse performances.
Theoretically, by reducing the influence of the classes probability to zero, the model performances will eventually reach the one of \textbf{\ref{sec:obj_only}}.
The following table reports the results and a comparison with the object only model.
\begin{table}[ht!]
    \begin{adjustwidth}{}{}
	    \centering
	    \small
	    \begin{tabular}{ |c|c|c| }
        \hline
        \textbf{Model} & \textbf{Top1 Tr/Val} & \textbf{Top3 Tr/Val}\\
        \hline
        model 104 & 92.56/87.09 & 98.93/95.73 \\
        Obj only & 87.42/84.13 & 96.41/94.30 \\
        Obj + injected probs & 84.67/81.23 & 93.25/91.23 \\
        \hline
        \end{tabular}
	    \label{tb:relevant-bias}
    \end{adjustwidth}
    \captionsetup{justification   = centering}
    \caption{Comparison between \textit{first-level}, \\\textit{object only} and \textit{offices as injected probabilities} models}
\end{table}

\subsubsection{Office's classes distribution as probability concatenated to object information}\label{sec:cls-distr-bias-concat}
The base concept of this model is the same of \textbf{\ref{sec:cls-distr-bias}}, the main difference is that the office information - always encoded as a vector of the \textit{classes distribution} (Def. \ref{def:cls_distr}) associated to the various offices - is now concatenated to the output of the \textit{object module} (\textbf{\ref{sec:object-module}}).
This should offer a bit more flexibility than the previous approach (\textbf{\ref{sec:cls-distr-bias}}) because the final classifier can adapt its weights associated to this part of the input, while previously this information was injected through an element-wise multiplication where no weights were involved.
\paragraph{Performances}
As expected, thanks to the flexibility added by having some trainable weights associated to the classes distribution of the office, this model performs significantly better than the alternative (\textbf{\ref{sec:cls-distr-bias}}).\\
The following table adds the results of this model to the previous table.
\begin{table}[ht!]
    \begin{adjustwidth}{}{}
	    \centering
	    \small
	    \begin{tabular}{ |c|c|c| }
        \hline
        \textbf{Model} & \textbf{Top1 Tr/Val} & \textbf{Top3 Tr/Val}\\
        \hline
        model 104 & 92.56/87.09 & 98.93/95.73 \\
        Obj only & 87.42/84.13 & 96.41/94.30 \\
        Obj + injected probs & 84.67/81.23 & 93.25/91.23 \\
        Obj + concatenated probs & 91.09/86.19 & 98.26/95.30 \\
        \hline
        \end{tabular}
	    \label{tb:relevant-bias-concat}
    \end{adjustwidth}
    \captionsetup{justification   = centering}
    \caption{Comparison between \textit{first-level}, \textit{object only}, \textit{offices as injected probabilities} and \textit{offices as concatenated probabilities} models}
\end{table}
\subsection{Second level}\label{sec:altern-lev2}
\hyperref[sec:2lev-model]{\textbf{Section \ref{sec:2lev-model}}} shows the "standard" model to perform a classification up to the second level of the classes' hierarchy.\\
The next subsection instead describes an alternative attempt made without using the first-level classification to refine the second-level one.

\subsubsection{Without first level prediction bias}\label{sec:altern-no-1cls-bias}
This model can be seen as a variant of the one described in \hyperref[sec:2lev-model]{\textbf{Section \ref{sec:2lev-model}}}, but the prediction of the second level is \textit{completely independent} from the first-level class (actual or predicted) of the document in question.
In this sense, the concept of this model is much more similar to the one of \hyperref[sec:1lev-model]{\textbf{Section \ref{sec:1lev-model}}} (i.e. first-level classification).
\paragraph{Model description}
Here, the \textit{first level module} is not present, making the \textit{second level module} totally unbiased.

The second-level classification is performed as in the beginning of the standard \textit{second-level model} (\textbf{\ref{sec:2lev-model}}): the office and the object pass through their respective modules, then the latter is flattened and its dimensionality reduced (as always\footnote{\label{ftnote:always} "always" refers to the models described in sections \ref{sec:1lev-model}, \ref{sec:2lev-model}, \ref{sec:obj_only} and \ref{sec:cls-distr-bias}}, using an apposite FC layer\footnotemark[\getrefnumber{ftnote:fc_layer}]).
Finally these are concatenated and, after applying some dropout, they are sent to the final classifier (i.e. a MLP).
\paragraph{Performances}\label{sec:secondnobiasperformances}
Unlike other models, the performances are in this case surprisingly slightly better than the second level task chosen model, requiring a deeper analysis to understand where and how this simpler model outperforms model 208 (\hyperref[sec:secondlevelperformances]{\textbf{Section \ref{sec:secondlevelperformances}}}). Taking a look at \hyperref[tb:secondnobias]{\textbf{Table \ref{tb:secondnobias}}} the model is able to snatch two full \textit{Top 1} validation accuracy points with respect to the chosen model. 

\begin{table}[ht!]
    \begin{adjustwidth}{}{}
	    \centering
	    \small
	    \begin{tabular}{ |c|c|c|c| }
        \hline
        \textbf{Model} & \textbf{Top1 Tr/Val} & \textbf{Top3 Tr/Val} & \textbf{Top5 Tr/Val}\\
        \hline
        model 208 & 80.30/77.71 & 91.84/87.49 & 95.31/90.54 \\
        Model No Bias &  83.96/79.85 & 93.32/89.34 & 95.60/92.14\\
        \hline
        \end{tabular}
    \end{adjustwidth}
    \captionsetup{justification   = centering}
    \caption{Comparison between \textit{second-level} and \textit{second-level no bias} models}
    \label{tb:secondnobias}
\end{table}

For a better insight we increased our level of analysis to the single class accuracy. The objective was to understand in which classes the two models perform the best given two quantitative measures:
\begin{itemize}
    \item \textbf{First class accuracy}: a measure (per class) of how accurate is the second level model in classifying a second level class at least in the correct first level.
    \item \textbf{Second class accuracy}: a measure (per class) of how accurate is the second level model in classifying a second level class in full precision.
\end{itemize}
Unfortunately this more in depth analysis did not give better insights. This is probably due to the incredibly near performances on the validation dataset and will be more in depth studied on the test dataset (\hyperref[sec:test]{\textbf{Section \ref{sec:test}}}).

\section{Tests}\label{sec:test}
\textit{CTT} company kindly provided us with a set of data completely detached from the previous dataset. This \textbf{test set} is in fact composed of the documents following the previous period, in particular going from mid May 2021 to mid July 2021. The presence of such data allowed us the access to a true \textbf{model assessment} phase for our final models.

\subsection{First Level}
Taking a look at the easier task, \hyperref[tb:firsttest]{\textbf{Table \ref{tb:firsttest}}} represents the accuracy comparison between validation and test set. The results obtained from \textbf{model 104} are quite good, reaching \textit{85.42\% Top 1} accuracy and \textit{93.63\% Top 3}. This further proves that the training process provided a good generalization capability to the model which leads to nice results over a new set of data.
\begin{table}[ht!]
    \begin{adjustwidth}{}{}
	    \centering
	    \small
	    \begin{tabular}{ |c|c|c| }
        \hline
        \textbf{Phase} & \textbf{Top1} & \textbf{Top3}\\
        \hline
        Validation & 87.09 & 95.73\\
        Test & 85.42 & 93.63\\
        \hline
        \end{tabular}
    \end{adjustwidth}
    \captionsetup{justification   = centering}
    \caption{Comparison between Model 104 \\\textit{validation} and \textit{test} performances}
    \label{tb:firsttest}
\end{table}

\hyperref[fig:heatfirst1]{\textbf{Figure \ref{fig:heatfirst1}}} displays the \textit{confusion matrix} over the test set exploiting the \textit{Top 1 prediction} of the model. First thing that stands out is the distribution of the samples which is very unbalanced, similarly to the original dataset, up to the point that \textit{class 5} has 0 samples. As far as concerns other classes, the low represented classes - \textit{3, 11 and 12} - are the ones where the mis-classification is higher. Other classes suffers the same trend of error, and this can be justified by errors made from the users - either on the class or the office - but also from some changes of competence between offices over documents during time. The latter reason also emerged during a meeting with Doc. Franchi, where a small live demo was set up. During the test, the \textit{Top 1} prediction of the model was incorrect using a known object and one possible document repository, but simply changing the latter was enough to get the correct prediction with \textit{99\%} reliability. This shows that the model has a nice generalization capability which, however, is very susceptible to the input data and this is obviously due to the data used to train the model. Nevertheless, even in the first test case, considering the \textit{Top 3} prediction was enough to have the correct answer with \textit{~30\%} reliability. The better accuracy of the model using the \textit{Top 3 prediction} can be seen in \hyperref[fig:heatfirst3]{\textbf{Figure \ref{fig:heatfirst3}}}. The confusion matrix highlights that all classes, including class 12, have more than 50\% accuracy with few misclassified samples only in the low represented classes. \hyperref[testclassdistrib]{\textbf{Figure \ref{testclassdistrib}}} shows for each class the prediction accuracy comparing the \textit{Top 1} and \textit{Top 3} prediction, suggesting that providing the latter to the user would for sure provide a trustworthy suggestion.

\subsection{Second Level}
Moving to the more complex task, \hyperref[tb:secondtest]{\textbf{Table \ref{tb:secondtest}}} reports the results obtained in the second level classification task. Also in this case, the accuracy of the model is similar to the one obtained during the process of validation.
\begin{table}[ht!]
    \begin{adjustwidth}{}{}
	    \centering
	    \small
	    \begin{tabular}{ |c|c|c|c| }
        \hline
        \textbf{Phase} & \textbf{Top1} & \textbf{Top3} & \textbf{Top5}\\
        \hline
        Validation & 77.71 & 87.49 & 90.54\\
        Test & 74.92 & 83.89 & 87.30\\
        
        \hline
        \end{tabular}
    \end{adjustwidth}
    \captionsetup{justification   = centering}
    \caption{Comparison between Model 208 \\\textit{validation} and \textit{test} performances}
    \label{tb:secondtest}
\end{table}

In this scenario providing a confusion matrix or representation of the accuracy over the \textit{118 classes} would not have been the optimal choice, so the focus of the analysis was shifted to more general statistics. In particular the \textit{Top 1} and \textit{Top 5} prediction will be taken into consideration and compared to analyze the performances of the model. \hyperref[pieplot]{\textbf{Figure \ref{pieplot}}} displays two pie plots: \hyperref[a]{\textbf{11(a)}} reports \textit{Top 1} prediction statistics, while \hyperref[b]{\textbf{11(b)}} depicts \textit{Top 5} prediction statistic.\\
Starting from the first one, the bigger portion - \textbf{37.04\%} - refers to the percentage of classes with \textit{0\% accuracy}, this is related to a huge number of classes that only have few samples in the test set as well as in the training set. This low represented data might not be correctly generalized by the model and lead to extremely poor accuracy. Nonetheless, \textbf{50\%} of classes have \textit{at least 25\% accuracy}, and \textbf{more than 25\%} have \textit{at least 50\% accuracy}; results that - considering a \textit{Top 1 prediction} over 118 classes - are not bad at all.\\
Considering the second plot the performances improve significantly. The number of classes with \textit{0\% accuracy} is lowered to \textbf{24.69\%}. The bigger portion - \textbf{39.51\%} - in this case refers to classes with over \textit{75\% accuracy}, and \textbf{more than 60\%} of classes have \textit{at least 50\% accuracy}. Similarly to the previous case, the \textit{Top 5 prediction} provides the user a viable suggestion from which to choose the class for the document.

\pagebreak

\subsection{Second level with/without bias comparison}
The unclear insights in analyzing the better performances of \hyperref[sec:altern-no-1cls-bias]{\textbf{Section \ref{sec:altern-no-1cls-bias}}} become clearer on a different dataset as the test set. The performances can be appreciated in \hyperref[tb:test-bias-nobias]{\textbf{Table \ref{tb:test-bias-nobias}}} where \textit{Model No Bias} achieves a result with little more than two full accuracy point over \textit{Model 208}. 
\begin{table}[ht!]
    \begin{adjustwidth}{}{}
	    \centering
	    \small
	    \begin{tabular}{ |c|c|c|c| }
        \hline
        \textbf{Model} & \textbf{Top1} & \textbf{Top3} & \textbf{Top5}\\
        \hline
        Model 208 & 74.92 & 83.89 & 87.30\\
        Model No Bias & 77.35 & 86.56 & 89.49\\
        \hline
        \end{tabular}
    \end{adjustwidth}
    \captionsetup{justification   = centering}
    \caption{Comparison between Model 208 and Model No Bias \textit{test} performances}
    \label{tb:test-bias-nobias}
\end{table}

The deeper analysis already attempted in \textbf{\ref{sec:altern-no-1cls-bias}} is reproduced in this case and the results are shown in \hyperref[nobiasvs41test]{\textbf{Figure \ref{nobiasvs41test}}}.
Such a behaviour shows the supremacy of the Model No Bias in many classes when talking about second level task (such as class 1, 4, 12, 13 and 15), demonstrating how an uncertain or erroneous first level bias leads to a worsened result with respect to a simpler and unbiased model. 
In fact, even if the biased model performs better in the first level task, the uncertainty penalizes the accuracy scores by a lot, while the unbiased model shows its robustness with less abrupt drops in accuracy.

Both the models are definitely performing well and both could be used, but at this point the preference falls on the no bias model. An undoubtedly important experiment to understand that a finer grained analysis can give rise to better model explainability.

\subsection{Inference Time}
A key and fundamental point that goes beyond the accuracy numbers and affect the model performances is the inference time. In fact the proposed solution should not only be precise, but should be able to provide the user a set of possible classes in a small interval of time. As presented in  \hyperref[sec:projectpurpose]{\textbf{Section \ref{sec:projectpurpose}}} and reported in \hyperref[fig:classinterface]{\textbf{Figure \ref{fig:classinterface}}}, currently the user has to click and navigate through the various levels of the hierarchy in order to find the correct class. If the model is too slow the task is easily solved by the user, on the other hand if the model rapidly provides an answer, it can be exploited to avoid searching.

\begin{table}[ht!]
    \begin{adjustwidth}{}{}
	    \centering
	    \small
	    \begin{tabular}{ |c|c| }
        \hline
        \textbf{Model} & \textbf{Inference time (\textit{sec})} \\
        \hline
        Model 104 & 0.002777 \\
        Model 208 & 0.006295 \\
        \hline
        \end{tabular}
    \end{adjustwidth}
    \captionsetup{justification   = centering}
    \caption{Inference time \textit{first} and \textit{second level} models}
    \label{tb:inf-time}
\end{table}

In order to get a fair estimate, the model was loaded on the \textit{CPU}, in this way it would be tested on a normal hardware available in any device. The time reported in \hyperref[tb:inf-time]{\textbf{Table \ref{tb:inf-time}}} are an average of 10 different tests.

Both architectures have a very small inference time, order of milliseconds, resulting in a very efficient solution. The users will be able to select the office, write the object and almost instantly get the result. If the model, in the 3/5 possible classes, provides the correct one the user will be able to select it without using the class hierarchy interface.

\section{Model Maintainability}
The purpose of this project is to provide a viable solution that can help the users in the classification task. This solution should adapt and evolve with changes that can happen inside the company (e.g. changes of competence of various offices). As time goes by, more and more data is handled and classified by the users, and this leads to new sets of entries that can be exploited to improve model's performances.\\
In case of changes of competences, it is possible to perform a retraining with all the data (past and new), but removing the records that are now incompatible with the new structure of the archive.\\
Otherwise, if the data distribution changes, but it is important not to "forget" what learnt so far, a retraining would do the job, but there exist some \textit{continual learning} strategies to achieve the same result in a more computationally efficient way.\\
Finally, in case the data distribution stays the same, it is possible to exploit the new data available with a \textbf{fine tuning} of the model.
% There are different approaches that can be used to update the model: it can be retrained from scratch using a bigger dataset, or it is possible to keep the current model. While the first alternative is more brutal, since we re-train the previous model, the second one keeps the current one and tries to improve it. This approach can be seen as a \textbf{fine tuning}, taking inspiration from the homonymous process that can be used for models such as pre-trained BERT.
In particular, trying to apply this idea to the proposed solution, a fine tuning on the \textit{second level model} was attempted.

The model was trained using the dataset presented in \hyperref[sec:dataset]{\textbf{Section \ref{sec:dataset}}}. The data was split into training and validation set. In this part of the analysis, the validation set is used as training set for the fine tuning with \textbf{7988} entries. Despite the small size of the training data and few epochs of training, the results lead to an improvement in the performances in the second level classification task over the test data (ref. \textbf{\ref{sec:test}}).

Here is reported the accuracy comparison over the test set considering the following models:
\begin{itemize}
    \item [A.] Model 208 (ref. \textbf{\ref{sec:2lev-model}}).
    \item [B.] Fine tuning of model \textbf{A}.
\end{itemize}
\begin{table}[ht!]
    \begin{adjustwidth}{}{}
	    \centering
	    \small
	    \begin{tabular}{ |c|c|c|c|c| }
        \hline
        \textbf{Model} & \textbf{Loss} & \textbf{\% Top1} & \textbf{\% Top3} & \textbf{\% Top5} \\
        \hline
        A & 1.82532 & 74.92 & 83.89 & 87.30 \\
        B & 1.30638 & 75.13 & 84.03 & 87.87 \\
        \hline
        \end{tabular}
        \captionsetup{justification = centering, singlelinecheck=false, margin=3cm}
	    \label{tb:finetuning}
    \end{adjustwidth}
    \caption{Comparison over test data of second level models}
\end{table}

\section{Comparison with Baselines}
Before drawing up the final conclusions, a comparison with a basic machine learning technique is long overdue. Such a comparison is a relevant tool to understand how difficult the task really is. In fact, if a naive model such as the \textit{Naive Bayes Classifier} is able to get an accuracy comparable to the one of our model, it becomes futile to use a more complex model such as ours.\\
The performance comparison between two different \textit{Naive Bayes Classifiers} (one per task) and our selected models on the validation and test accuracy metrics is shown in \hyperref[tb:baseline]{\textbf{Table 14}}. Such results highlight how the tasks at hand are not incredibly difficult, with the simpler model being absolutely comparable to the complex model.\\
It is at this point of the discussion important to admit that the proposed model is probably more complex than needed, giving also a higher inference time for the first level task as shown once again in \hyperref[tb:baseline]{\textbf{Table 14}}. It is nevertheless interesting to notice how the Naive Bayes inference time gets bigger once the number of classes per task gets higher (Naive Bayes inference time is slower than the Neural Model in the second task). To conclude this short analysis, the task at hand results to be simple to solve, not needing an elaborated response as the one we proposed. We are nevertheless satisfied to have developed from scratch our models, hands on, comparing different architectures and getting in contact with the pain and joy of Natural Language Processing in Machine Learning.

\begin{table}[ht!]
\centering
	    \small
	    \begin{adjustwidth}{1cm}
	                
\subfloat{\begin{tabular}{ |c|c|c|c|}
        \hline
        \textbf{Task} &\textbf{Model 104} & \textbf{Naive Bayes} & \textbf{bert-base-italian-cased}\\
        \hline
        Validation (First) & 87.09/95.73 & 83.61/95.36 & 88.28/96.63\\ 
        Test (First) & 85.42/93.63 & 84.91/94.86 & 88.83/95.37\\ 
        Inference Time & 0.002777 & 0.000751 & 0.317788\\ 
        \hline
        \end{tabular}}
	    \end{adjustwidth}
\newline
\subfloat{\begin{tabular}{ |c|c|c|c|}
        \hline
        \textbf{Task} & \textbf{Model 208}  & \textbf{Model No Bias} & \textbf{Naive Bayes} \\
        \hline
        Validation (Second) & 77.71/87.49/90.54 & 79.85/89.34/92.14 & 74.12/85.64/89.15 \\ 
        Test (Second) & 74.92/83.89/87.30 & 77.35/86.56/89.49 & 76.14/85.56/88.44 \\ 
        Inference Time & 0.006295 & 0.006003 & 0.006411 \\ 
        \hline
        \end{tabular}}
    \captionsetup{justification = centering}
    \caption{Comparison between complex model and baseline \\accuracy result are given in format top1 / top3 ( / top5)}
    \label{tb:baseline}
\end{table}
\pagebreak
\section{Conclusions and Future Development}
In this report different solutions to solve Document Classification in public administration have been analyzed. A baseline analysis using the basic \textit{Naive Bayes Classifier} showed how the tasks were not particularly difficult to handle even with simple models, but nevertheless the different experiments for the \textit{first and second level} classification tasks lead to interesting results and a huge personal growth. In the first case, the easier one with only 15 classes, the model is able to reach high performances - \textit{93.63\% Top 3 accuracy} - and also provide nice results for all the classes, going beyond their unbalanced distribution. The second one instead was the most challenging task given the significantly higher number of classes and a much sparser distribution. Nevertheless, different solutions provided interesting results that went beyond the expectations, reaching \textit{87.30\% accuracy} exploiting a Top 5 prediction. The proposed solutions proved to be a viable integration to the current process of document classification providing both speed and precision. 
\textit{CTT} during the whole period showed to be excited about the project and surprised by the results achieved. We would like to thank them for the availability and support. We would also like to thank professor Attardi for the critical review and experienced hints, they really pushed us to learn from our mistakes and not fall in similar errors or problems in our future careers.

Last but not least, we will keep working on the project creating a more general solution. The idea is to provide a service that can be used by any company that, with the correctly tuned model, will be able to exploit its prediction to improve the process of classification.

\newpage
\section{References}
\printbibliography[heading=none]

\newpage
\section{Figures}
\begin{figure}[ht!]
    \begin{adjustwidth}{-3.5cm}{}
    	    \begin{center}
        \includegraphics[width=1.5\textwidth]{interface.png}
            \end{center}
    \end{adjustwidth}
    \captionsetup{justification = centering}
    \caption{Public administration user interface}
    \label{fig:interface}
\end{figure}

\begin{figure}[ht!]
    \begin{adjustwidth}{-2cm}{}
    	    \begin{center}
        \includegraphics[width=1.3\textwidth]{class_interface.png}
            \end{center}
    \end{adjustwidth}
    \captionsetup{justification = centering}
    \caption{Classes hierarchy user interface}
    \label{fig:classinterface}
\end{figure}

\pagebreak

\begin{figure}[ht!]
        \begin{adjustwidth}{-3.2cm}{}
    	    \begin{center}
        \includegraphics[width=1.5\textwidth]{#104.png}
            \end{center}
	    \end{adjustwidth}
        \caption{Model 104 training/validation plots}
        \label{fig:model104}
\end{figure}

\begin{figure}[ht!]
        \begin{adjustwidth}{-3.2cm}{}
    	    \begin{center}
        \includegraphics[width=1.5\textwidth]{#208.png}
            \end{center}
	    \end{adjustwidth}
        \caption{Model 208 training/validation plots}
        \label{fig:model200}
\end{figure}
\newpage
\pagenumbering{gobble}
\begin{figure}[ht!]
        \begin{adjustwidth}{-3.2cm}{}
    	    \begin{center}
        \includegraphics[width=1.45\textwidth]{heatmap1.png}
            \end{center}
	    \end{adjustwidth}
	    \captionsetup{justification   = centering}
        \caption{Heatmap for Test Set on First level task (\textit{Top 1}) \\y axis: \textit{ground truth} - x axis: \textit{model prediction}}
        \label{fig:heatfirst1}
\end{figure}

\begin{figure}[ht!]
        \begin{adjustwidth}{-3.2cm}{}
    	    \begin{center}
        \includegraphics[width=1.45\textwidth]{heatmap3.png}
            \end{center}
	    \end{adjustwidth}
	    \captionsetup{justification   = centering}
        \caption{Heatmap for Test Set on First level task (\textit{Top 3) \\y axis: \textit{ground truth} - x axis: \textit{model prediction}}}
        \label{fig:heatfirst3}
\end{figure}

\begin{figure}[!tbp]
  \centering
  \subfloat[Top 1 Accuracy]{\includegraphics[width=0.7\textwidth]{class_distr1.png}\label{fig:before}}
  \hfill
  \subfloat[Top 3 Accuracy]{\includegraphics[width=0.7\textwidth]{class_distr3.png}\label{fig:after}}
  \captionsetup{justification   = centering}
\caption{\textit{Top 1} vs \textit{Top 3} first class task distribution \\(NB. the class are indexed starting from 0)}
\label{testclassdistrib}
\end{figure}

\begin{figure}[!tbp]
  \centering
  \subfloat[First class Top 1 accuracy ]{\includegraphics[width=0.7\textwidth]{acc_per_class_first_task.png}}
  \hfill
  \subfloat[Second class Top 1 accuracy ]{\includegraphics[width=0.7\textwidth]{acc_per_class_second_task.png}}
    \captionsetup{justification   = centering}
    \caption{\textit{First class} vs \textit{Second class} accuracy comparison between with/out bias (see \hyperref[sec:secondnobiasperformances]{\textbf{Section \ref{sec:secondnobiasperformances}}})}
\label{nobiasvs41test}
\end{figure}

\begin{figure}[!tbp]
  \centering
  \begin{adjustwidth}{+2.9cm}{}
  \subfloat[Top 1 accuracy pieplot]{\includegraphics[width=0.7\textwidth]{pieplot1.png}}\label{a}
  \end{adjustwidth}
  \hfill
  \begin{adjustwidth}{+2.5cm}{}
  \subfloat[Top 5 accuracy pieplot]{\includegraphics[width=0.65\textwidth]{pieplot5.png}}\label{b}
  \end{adjustwidth}
    \captionsetup{justification   = centering}
    \caption{\textit{Top 1} and \textit{Top 5} accuracy pieplots for Second Level Task testing}
\label{pieplot}
\end{figure}

\begin{figure}[ht!]
        \begin{adjustwidth}{0cm}{}
    	    \begin{center}
        \includegraphics[width=1\textwidth]{first_model.png}
            \end{center}
	    \end{adjustwidth}
	    \captionsetup{justification   = centering}
        \caption{First Level Model Architecture}
        \label{fig:archifirst}
\end{figure}

\begin{figure}[ht!]
        \begin{adjustwidth}{-3cm}{}
    	    \begin{center}
        \includegraphics[width=1.45\textwidth]{second_model.png}
            \end{center}
	    \end{adjustwidth}
	    \captionsetup{justification   = centering}
        \caption{Second Level Model Architecture}
        \label{fig:archisecond}
\end{figure}
\end{document}